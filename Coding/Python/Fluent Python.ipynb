{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd64b70",
   "metadata": {},
   "source": [
    "# Fluent Python by Luciano Ramalho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af114e38",
   "metadata": {},
   "source": [
    "## Part I: Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Magic Methods (Dunder) & FrenchDeck Example\n",
    "import collections\n",
    "from random import choice\n",
    "\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits \n",
    "                      for rank in self.ranks]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]\n",
    "\n",
    "# Demo of FrenchDeck with magic methods\n",
    "deck = FrenchDeck()\n",
    "\n",
    "print(f\"Deck length: {len(deck)}\")  # 52\n",
    "print(f\"First card: {deck[0]}\")     # Card(rank='2', suit='spades')\n",
    "print(f\"Last card: {deck[-1]}\")     # Card(rank='A', suit='hearts')\n",
    "print(f\"Random card: {choice(deck)}\")  # Random card from deck\n",
    "\n",
    "print(\"\\nTop 3 cards:\")\n",
    "print(deck[:3])  # [Card(rank='2', suit='spades'), ...]\n",
    "print(\"\\nAces (every 13th card):\")\n",
    "print(deck[12::13])  # All aces\n",
    "\n",
    "print(\"\\nIterate deck (first 5 cards):\")\n",
    "for card in deck[:5]:\n",
    "    print(card)\n",
    "\n",
    "print(\"\\nReverse iteration (last 5 cards):\")\n",
    "for card in reversed(deck[-5:]):\n",
    "    print(card)\n",
    "\n",
    "print(f\"\\n'Q of hearts' in deck: {'Q' in deck and 'hearts' in deck}\")  # True/False\n",
    "\n",
    "# Custom sorting: Spades > Hearts > Diamonds > Clubs\n",
    "suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0)\n",
    "def spades_high(card):\n",
    "    rank_value = FrenchDeck.ranks.index(card.rank)\n",
    "    return rank_value * len(suit_values) + suit_values[card.suit]\n",
    "\n",
    "sorted_deck = sorted(deck, key=spades_high)\n",
    "print(\"\\nSorted deck (lowest to highest):\")\n",
    "print(f\"Lowest: {sorted_deck[0]}\")   # Card(rank='2', suit='clubs')\n",
    "print(f\"Highest: {sorted_deck[-1]}\")  # Card(rank='A', suit='spades')\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dunder Methods**: `__len__` and `__getitem__` enable Pythonic behavior (e.g., `len()`, `[]`).\n",
    "2. **Zero Boilerplate**: By implementing two methods, the class works with `random.choice`, slicing, iteration, and `in`.\n",
    "3. **Delegation**: `__getitem__` delegates to the list's `__getitem__`, enabling slicing and reverse iteration.\n",
    "4. **Custom Sorting**: Combine `sorted()` with a key function to define ranking logic (e.g., `spades_high`).\n",
    "5. **Pythonic Design**: Follows the Data Model to integrate with built-in functions, reducing the need for custom methods.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7153779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Dunder Methods & Data Model Examples\n",
    "import collections\n",
    "import math\n",
    "from random import choice\n",
    "\n",
    "# === FrenchDeck Example: Emulating Built-in Sequences ===\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits \n",
    "                      for rank in self.ranks]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]\n",
    "\n",
    "# === Vector Example: Emulating Numeric Types ===\n",
    "class Vector:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Vector({self.x!r}, {self.y!r})'\n",
    "    \n",
    "    def __abs__(self):\n",
    "        return math.hypot(self.x, self.y)\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return bool(abs(self))  # Returns False if magnitude is 0\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Vector(self.x + other.x, self.y + other.y)\n",
    "    \n",
    "    def __mul__(self, scalar):\n",
    "        return Vector(self.x * scalar, self.y * scalar)\n",
    "\n",
    "# === Demo Code ===\n",
    "deck = FrenchDeck()\n",
    "v1 = Vector(2, 4)\n",
    "v2 = Vector(2, 1)\n",
    "\n",
    "# FrenchDeck Features\n",
    "print(\"FrenchDeck Demo:\")\n",
    "print(f\"Deck length: {len(deck)}\")  # 52\n",
    "print(f\"First card: {deck[0]}\")     # Card(rank='2', suit='spades')\n",
    "print(f\"Random card: {choice(deck)}\")  # Random card\n",
    "print(f\"Top 3 cards: {deck[:3]}\")   # First three cards\n",
    "\n",
    "# Vector Features\n",
    "print(\"\\nVector Demo:\")\n",
    "print(f\"v1 + v2 = {v1 + v2}\")       # Vector(4, 5)\n",
    "print(f\"abs(v1) = {abs(v1)}\")       # 4.472...\n",
    "print(f\"v * 3 = {v1 * 3}\")          # Vector(6, 12)\n",
    "print(f\"bool(Vector(0,0)) = {bool(Vector(0, 0))}\")  # False\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dunder Methods Power**: Implementing `__len__` and `__getitem__` makes your class behave like built-in sequences (supports len(), indexing, slicing, iteration).\n",
    "2. **Composition Over Inheritance**: FrenchDeck delegates to a list (`self._cards`) rather than inheriting from list.\n",
    "3. **Operator Overloading**: Use `__add__`, `__mul__`, etc., to define custom behavior for operators (+, *, etc.).\n",
    "4. **String Representation**:\n",
    "   - `__repr__`: Unambiguous, for debugging/reconstruction (e.g., `Vector(2, 4)`).\n",
    "   - `__str__`: Human-readable, used by `print()`. Prefer `__repr__` if only one is implemented.\n",
    "5. **Truth Value Testing**: Define `__bool__` to control truthiness (e.g., `if Vector(0, 0): ...` returns False).\n",
    "6. **Performance Note**: For simple truth checks, `bool(self.x or self.y)` is faster than `abs()` but less readable.\n",
    "7. **Data Model Compliance**: Follows Python's data model to integrate with core features (e.g., `len()`, `in`, `sorted()`).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Dunder Methods & Data Model Examples\n",
    "import collections\n",
    "import math\n",
    "from random import choice\n",
    "\n",
    "# === FrenchDeck Example: Emulating Built-in Sequences ===\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits \n",
    "                      for rank in self.ranks]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]\n",
    "\n",
    "# === Vector Example: Emulating Numeric Types ===\n",
    "class Vector:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Vector({self.x!r}, {self.y!r})'\n",
    "    \n",
    "    def __abs__(self):\n",
    "        return math.hypot(self.x, self.y)\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return bool(abs(self))  # Returns False if magnitude is 0\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Vector(self.x + other.x, self.y + other.y)\n",
    "    \n",
    "    def __mul__(self, scalar):\n",
    "        return Vector(self.x * scalar, self.y * scalar)\n",
    "\n",
    "# === Demo Code ===\n",
    "deck = FrenchDeck()\n",
    "v1 = Vector(2, 4)\n",
    "v2 = Vector(2, 1)\n",
    "\n",
    "# FrenchDeck Features\n",
    "print(\"FrenchDeck Demo:\")\n",
    "print(f\"Deck length: {len(deck)}\")  # 52\n",
    "print(f\"First card: {deck[0]}\")     # Card(rank='2', suit='spades')\n",
    "print(f\"Random card: {choice(deck)}\")  # Random card\n",
    "print(f\"Top 3 cards: {deck[:3]}\")   # First three cards\n",
    "\n",
    "# Vector Features\n",
    "print(\"\\nVector Demo:\")\n",
    "print(f\"v1 + v2 = {v1 + v2}\")       # Vector(4, 5)\n",
    "print(f\"abs(v1) = {abs(v1)}\")       # 4.472...\n",
    "print(f\"v * 3 = {v1 * 3}\")          # Vector(6, 12)\n",
    "print(f\"bool(Vector(0,0)) = {bool(Vector(0, 0))}\")  # False\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dunder Methods Power**: Implementing `__len__` and `__getitem__` makes your class behave like built-in sequences (supports len(), indexing, slicing, iteration).\n",
    "2. **Composition Over Inheritance**: FrenchDeck delegates to a list (`self._cards`) rather than inheriting from list.\n",
    "3. **Operator Overloading**: Use `__add__`, `__mul__`, etc., to define custom behavior for operators (+, *, etc.).\n",
    "4. **String Representation**:\n",
    "   - `__repr__`: Unambiguous, for debugging/reconstruction (e.g., `Vector(2, 4)`).\n",
    "   - `__str__`: Human-readable, used by `print()`. Prefer `__repr__` if only one is implemented.\n",
    "5. **Truth Value Testing**: Define `__bool__` to control truthiness (e.g., `if Vector(0, 0): ...` returns False).\n",
    "6. **Performance Note**: For simple truth checks, `bool(self.x or self.y)` is faster than `abs()` but less readable.\n",
    "7. **Data Model Compliance**: Follows Python's data model to integrate with core features (e.g., `len()`, `in`, `sorted()`).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f47c24",
   "metadata": {},
   "source": [
    "### CHAPTER 2: An Array of Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0250b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Built-in Sequences & Advanced Concepts\n",
    "import array\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "# 1. List Comprehensions vs Generator Expressions\n",
    "squares_list = [x**2 for x in range(5)]  # Creates list immediately\n",
    "squares_gen = (x**2 for x in range(5))  # Lazy evaluation generator\n",
    "\n",
    "# 2. Tuples: Records vs Immutable Lists\n",
    "point = (10, 20)  # Record (fixed-size, heterogeneous)\n",
    "coordinates = (1, 2, 3)  # Immutable list (fixed-size, homogeneous)\n",
    "\n",
    "# 3. Sequence Unpacking & Patterns (Python 3.10+)\n",
    "def sequence_match(seq):\n",
    "    match seq:\n",
    "        case [x, y]: return f\"Two elements: {x}, {y}\"\n",
    "        case [x, y, z]: return f\"Three elements: {x}, {y}, {z}\"\n",
    "        case _: return \"Unknown pattern\"\n",
    "\n",
    "# 4. Slicing: Read & Write\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "numbers[1:3] = [20, 30]  # Replace slice\n",
    "\n",
    "# 5. Specialized Sequences\n",
    "float_array = array.array('d', [1.1, 2.2, 3.3])  # Flat sequence (compact storage)\n",
    "queue = deque([1, 2, 3])  # Efficient appends/pops from both ends\n",
    "\n",
    "# 6. Performance Comparison\n",
    "list_size = sys.getsizeof([1, 2, 3])\n",
    "tuple_size = sys.getsizeof((1, 2, 3))\n",
    "array_size = sys.getsizeof(float_array)\n",
    "\n",
    "# Demo Execution\n",
    "print(\"List Comprehension:\", squares_list)\n",
    "print(\"Generator Expression (converted to list):\", list(squares_gen))\n",
    "print(\"\\nTuple as Record:\", point)\n",
    "print(\"Tuple as Immutable List:\", coordinates)\n",
    "print(\"\\nSequence Matching Examples:\")\n",
    "print(sequence_match([1, 2]))\n",
    "print(sequence_match([1, 2, 3]))\n",
    "print(\"\\nAfter Slice Assignment:\", numbers)\n",
    "print(\"\\nSpecialized Sequences:\")\n",
    "print(\"Float Array:\", float_array)\n",
    "print(\"Deque (FIFO-ready):\", queue)\n",
    "print(\"\\nMemory Comparison (bytes):\")\n",
    "print(f\"List: {list_size}, Tuple: {tuple_size}, Array: {array_size}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **List Comprehensions vs Generators**:\n",
    "   - Use `[]` for immediate computation, `()` for lazy evaluation.\n",
    "   - Generators save memory for large datasets.\n",
    "\n",
    "2. **Tuples**:\n",
    "   - Immutable but faster than lists for fixed data.\n",
    "   - Use as records (namedtuples recommended for clarity) or for hashable keys.\n",
    "\n",
    "3. **Sequence Unpacking**:\n",
    "   - `*` captures variable elements: `head, *rest = [1,2,3,4]`\n",
    "   - Python 3.10+ pattern matching enables expressive sequence analysis.\n",
    "\n",
    "4. **Slicing**:\n",
    "   - Lists support slice assignment: `lst[1:3] = [new_values]`\n",
    "   - Tuples are immutable (no slice assignment).\n",
    "\n",
    "5. **Specialized Sequences**:\n",
    "   - `array.array`: Compact storage for homogeneous data (flat vs container).\n",
    "   - `collections.deque`: Thread-safe, fast O(1) appends/pops from both ends.\n",
    "\n",
    "6. **Performance**:\n",
    "   - Tuples are ~40% smaller than lists for small data.\n",
    "   - Flat sequences (arrays) use ~1/5th the memory of list/tuple equivalents.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: List Comprehensions & Generator Expressions\n",
    "import sys\n",
    "\n",
    "# 1. Basic List Comprehension\n",
    "symbols = '$¢£¥€¤'\n",
    "codes = [ord(symbol) for symbol in symbols]  # List comprehension\n",
    "print(\"List Comprehension Output:\", codes)\n",
    "\n",
    "# 2. Generator Expression (Lazy Evaluation)\n",
    "gen_codes = (ord(symbol) for symbol in symbols)  # Generator expression\n",
    "print(\"Generator Expression Output (converted to list):\", list(gen_codes))\n",
    "\n",
    "# 3. Filtering with List Comprehension\n",
    "beyond_ascii = [ord(s) for s in symbols if ord(s) > 127]\n",
    "print(\"\\nFiltered Unicode Codes (>127):\", beyond_ascii)\n",
    "\n",
    "# 4. Equivalent with map/filter (Less Readable)\n",
    "beyond_ascii_map = list(filter(lambda c: c > 127, map(ord, symbols)))\n",
    "print(\"Filtered with map/filter:\", beyond_ascii_map)\n",
    "\n",
    "# 5. Cartesian Product with List Comprehension\n",
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "cartesian_product = [(color, size) for color in colors for size in sizes]\n",
    "print(\"\\nCartesian Product:\", cartesian_product)\n",
    "\n",
    "# 6. Scope in Comprehensions (Python 3)\n",
    "x = 'ABC'\n",
    "codes = [ord(x) for x in x]  # Shadows outer x inside comprehension\n",
    "print(f\"\\nOuter x after comprehension: '{x}'\")  # Original value preserved\n",
    "print(\"Comprehension result:\", codes)\n",
    "\n",
    "# 7. Walrus Operator in Generator Expression (Python 3.8+)\n",
    "last = None\n",
    "codes = [last := ord(c) for c in x]  # Assigns and captures 'last'\n",
    "print(\"\\nValue of 'last' after walrus operator:\", last)\n",
    "\n",
    "# 8. Memory Comparison\n",
    "list_size = sys.getsizeof(codes)\n",
    "gen_size = sys.getsizeof((ord(s) for s in symbols))\n",
    "print(f\"\\nMemory Usage (bytes):\")\n",
    "print(f\"List: {list_size}, Generator: {gen_size}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Readability**:\n",
    "   - List comprehensions (`[x for x in ...]`) are explicit and self-documenting for list creation.\n",
    "   - Avoid overusing nested listcomps; prefer plain loops for complex logic.\n",
    "\n",
    "2. **Performance**:\n",
    "   - Listcomps are often faster than `map`/`filter` for Python code (C-level optimizations help).\n",
    "   - Generators (`(x for x in ...)`) save memory by producing items lazily.\n",
    "\n",
    "3. **Scope**:\n",
    "   - Variables in comprehensions are local to the expression (outer variables preserved).\n",
    "   - Walrus operator (`:=`) allows capturing values post-comprehension.\n",
    "\n",
    "4. **Use Cases**:\n",
    "   - Use listcomps for new list creation.\n",
    "   - Use generator expressions for streaming/iterating without full list allocation.\n",
    "   - Cartesian products and filtering are natural fits for listcomps.\n",
    "\n",
    "5. **Memory Efficiency**:\n",
    "   - Generators reduce memory overhead for large datasets.\n",
    "   - Listcomps materialize the entire sequence upfront.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a455d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: List Comprehensions, Generators, and Tuples\n",
    "import array\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "# 1. List Comprehensions vs Generator Expressions\n",
    "symbols = '$¢£¥€¤'\n",
    "codes_list = [ord(symbol) for symbol in symbols]  # List comprehension\n",
    "codes_gen = (ord(symbol) for symbol in symbols)    # Generator expression\n",
    "\n",
    "# 2. Cartesian Product with List Comprehension\n",
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "tshirts = [(color, size) for color in colors for size in sizes]  # By color then size\n",
    "tshirts_by_size = [(size, color) for size in sizes for color in colors]  # By size then color\n",
    "\n",
    "# 3. Generator Expression for Memory Efficiency\n",
    "float_array = array.array('d', (ord(s) for s in symbols))  # Generator feeds array\n",
    "\n",
    "# 4. Tuples as Records (Immutable Data Structures)\n",
    "lax_coordinates = (33.9425, -118.408056)  # Latitude/longitude tuple\n",
    "tokyo_data = ('Tokyo', 2003, 32_450, 0.66, 8014)  # City, year, population, change, area\n",
    "\n",
    "# 5. Tuples as Immutable Lists (with Caveats)\n",
    "a = (10, 'alpha', [1, 2])  # Tuple with mutable list\n",
    "b = (10, 'alpha', [1, 2])  # Initially equal to a\n",
    "b[-1].append(99)           # Modify mutable element in b\n",
    "are_equal = a == b         # Now a and b differ\n",
    "\n",
    "# 6. Hashability Check (Fixed vs Mutable Tuples)\n",
    "def is_hashable(obj):\n",
    "    try: hash(obj)\n",
    "    except TypeError: return False\n",
    "    return True\n",
    "\n",
    "tf = (10, 'alpha', (1, 2))  # Fully immutable\n",
    "tm = (10, 'alpha', [1, 2])  # Contains mutable list\n",
    "\n",
    "# Demo Execution\n",
    "print(\"List Comprehension Output:\", codes_list)\n",
    "print(\"Generator Expression (converted to list):\", list(codes_gen))\n",
    "print(\"\\nCartesian Product (color, size):\", tshirts)\n",
    "print(\"Cartesian Product (size, color):\", tshirts_by_size)\n",
    "print(\"\\nFloat Array from Generator:\", float_array)\n",
    "print(\"\\nTuple as Record - Tokyo Data:\", tokyo_data)\n",
    "print(\"Tuple with Mutable Element (a vs b):\", are_equal)\n",
    "print(\"\\nHashability Check:\")\n",
    "print(f\"Fully immutable tuple: {is_hashable(tf)}\")\n",
    "print(f\"Tuple with list: {is_hashable(tm)}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **List Comprehensions vs Generators**:\n",
    "   - Use `[]` for immediate list creation, `()` for lazy evaluation.\n",
    "   - Generators save memory for large datasets (e.g., `array.array('d', (ord(s)...)`).\n",
    "\n",
    "2. **Cartesian Products**:\n",
    "   - Listcomps generate full product lists: `[(color, size) for...]`.\n",
    "   - Generator expressions avoid memory overhead when iterating directly.\n",
    "\n",
    "3. **Tuples**:\n",
    "   - **As Records**: Fixed-size, ordered fields (e.g., coordinates, city data).\n",
    "   - **As Immutable Lists**: Memory-efficient, hashable (if all elements are immutable).\n",
    "   - **Caveat**: Tuples with mutable elements (e.g., lists) can change indirectly.\n",
    "\n",
    "4. **Performance**:\n",
    "   - Tuples use ~40% less memory than lists for small data.\n",
    "   - Listcomps are faster than `map/filter` for Python-level code.\n",
    "   - Generators avoid allocating full lists for large datasets.\n",
    "\n",
    "5. **Hashability**:\n",
    "   - Only fully immutable tuples are hashable (can be dict keys/set elements).\n",
    "   - Use `hash()` or a helper function to verify immutability.\n",
    "\n",
    "6. **Unpacking**:\n",
    "   - Tuples support unpacking for clean variable assignment: `city, year, pop = tokyo_data`.\n",
    "   - Use `_` as a dummy variable for ignored values: `for country, _ in traveler_ids`.\n",
    "\n",
    "7. **Design Patterns**:\n",
    "   - Prefer tuples for data that shouldn't change (e.g., configuration, constants).\n",
    "   - Use listcomps for small datasets; generators for streaming/large data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d44133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Tuples, List Comprehensions, and Generators in Action\n",
    "import collections\n",
    "import math\n",
    "from random import choice\n",
    "import sys\n",
    "\n",
    "# === FrenchDeck Example with List Comprehension ===\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits \n",
    "                      for rank in self.ranks]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]\n",
    "\n",
    "# === Vector Example with Special Methods ===\n",
    "class Vector:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Vector({self.x!r}, {self.y!r})'\n",
    "    \n",
    "    def __abs__(self):\n",
    "        return math.hypot(self.x, self.y)\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return bool(abs(self))\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Vector(self.x + other.x, self.y + other.y)\n",
    "    \n",
    "    def __mul__(self, scalar):\n",
    "        return Vector(self.x * scalar, self.y * scalar)\n",
    "\n",
    "# === Tuples as Records and Immutable Lists ===\n",
    "lax_coordinates = (33.9425, -118.408056)  # Tuple as record\n",
    "immutable_list = (10, 'alpha', (1, 2))     # Fully immutable\n",
    "mutable_tuple = (10, 'alpha', [1, 2])      # Contains mutable list\n",
    "\n",
    "# === Cartesian Products ===\n",
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "\n",
    "# List comprehension (immediate evaluation)\n",
    "tshirts_list = [(color, size) for color in colors for size in sizes]\n",
    "\n",
    "# Generator expression (lazy evaluation)\n",
    "tshirts_gen = ((color, size) for color in colors for size in sizes)\n",
    "\n",
    "# === Pattern Matching with Sequences (Python 3.10+) ===\n",
    "def handle_message(message):\n",
    "    match message:\n",
    "        case ['BEEPER', freq, times]: return f\"Beep {times} times at {freq}Hz\"\n",
    "        case ['NECK', angle]: return f\"Rotate neck to {angle}°\"\n",
    "        case ['LED', id, intensity]: return f\"Set LED {id} brightness to {intensity}\"\n",
    "        case _: return \"Unknown command\"\n",
    "\n",
    "# === Demo Execution ===\n",
    "deck = FrenchDeck()\n",
    "v1 = Vector(2, 4)\n",
    "v2 = Vector(2, 1)\n",
    "\n",
    "print(\"FrenchDeck Features:\")\n",
    "print(f\"Random card: {choice(deck)}\")\n",
    "print(f\"Top 3 cards: {deck[:3]}\")\n",
    "\n",
    "print(\"\\nVector Operations:\")\n",
    "print(f\"v1 + v2 = {v1 + v2}\")\n",
    "print(f\"abs(v1) = {abs(v1)}\")\n",
    "print(f\"v1 * 3 = {v1 * 3}\")\n",
    "\n",
    "print(\"\\nTuples as Records:\")\n",
    "print(\"Coordinates:\", lax_coordinates)\n",
    "print(\"Immutable tuple:\", immutable_list)\n",
    "print(\"Mutable tuple (after modification):\", (mutable_tuple[0], mutable_tuple[1], mutable_tuple[2] + [99]))\n",
    "\n",
    "print(\"\\nCartesian Product:\")\n",
    "print(\"List comprehension:\", tshirts_list)\n",
    "print(\"Generator expression (converted):\", list(tshirts_gen))\n",
    "\n",
    "print(\"\\nPattern Matching Examples:\")\n",
    "print(handle_message(['BEEPER', 440, 3]))\n",
    "print(handle_message(['NECK', 45]))\n",
    "print(handle_message(['LED', 1, 0.7]))\n",
    "\n",
    "# === Memory Comparison ===\n",
    "list_size = sys.getsizeof([1, 2, 3])\n",
    "tuple_size = sys.getsizeof((1, 2, 3))\n",
    "print(f\"\\nMemory Usage (bytes): List={list_size}, Tuple={tuple_size}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **List Comprehensions**:\n",
    "   - `[]` builds lists immediately (good for small datasets).\n",
    "   - Use for filtering/transforming sequences (e.g., `[x**2 for x in range(5)]`).\n",
    "\n",
    "2. **Generator Expressions**:\n",
    "   - `()` yields items lazily (memory-efficient for large datasets).\n",
    "   - Ideal for streaming or one-time iteration (e.g., `sum((x**2 for x in range(1000000)))`).\n",
    "\n",
    "3. **Tuples**:\n",
    "   - **As Records**: Fixed-size, ordered data (e.g., coordinates, database rows).\n",
    "   - **As Immutable Lists**: Hashable if all elements are immutable (can be dict keys).\n",
    "   - **Caveat**: Tuples with mutable elements (e.g., lists) can change indirectly.\n",
    "\n",
    "4. **Special Methods**:\n",
    "   - `__add__`, `__mul__` enable operator overloading for custom types.\n",
    "   - `__repr__` provides unambiguous string representation for debugging.\n",
    "\n",
    "5. **Pattern Matching (Python 3.10+)**:\n",
    "   - `match/case` simplifies complex conditionals with destructuring (e.g., handling nested data structures).\n",
    "\n",
    "6. **Performance**:\n",
    "   - Tuples use ~40% less memory than lists for small data.\n",
    "   - Generators avoid memory overhead for large Cartesian products.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458bca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Sequences, Pattern Matching, and Slicing Examples\n",
    "import sys\n",
    "\n",
    "# 1. Pattern Matching with Sequences (Python 3.10+)\n",
    "def handle_command(command):\n",
    "    match command:\n",
    "        case ['BEEPER', freq, times]: return f\"Beep {times}x at {freq}Hz\"\n",
    "        case ['NECK', angle]: return f\"Rotate neck to {angle}°\"\n",
    "        case ['LED', id, intensity]: return f\"Set LED {id} brightness to {intensity}\"\n",
    "        case _: return \"Unknown command\"\n",
    "\n",
    "# 2. Cartesian Products with List Comprehensions\n",
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "tshirts_list = [(c, s) for c in colors for s in sizes]  # List comprehension\n",
    "tshirts_gen = ((c, s) for c in colors for s in sizes)   # Generator expression\n",
    "\n",
    "# 3. Slicing Examples\n",
    "s = 'bicycle'\n",
    "slice_examples = {\n",
    "    \"Basic slice\": s[2:5],\n",
    "    \"Full step\": s[::3],\n",
    "    \"Reverse\": s[::-1],\n",
    "    \"Custom slice\": s[1:6:2]\n",
    "}\n",
    "\n",
    "# 4. Named Slice Objects (Invoice Example)\n",
    "invoice = \"\"\"1909 Pimoroni PiBrella $17.50 3 $52.50\n",
    "1489 6mm Tactile Switch x20 $4.95 2 $9.90\"\"\"\n",
    "SKU = slice(0, 6)\n",
    "PRICE = slice(40, 52)\n",
    "\n",
    "# 5. Tuples as Records\n",
    "lax_coordinates = (33.9425, -118.408056)\n",
    "city, year, pop, chg, area = ('Tokyo', 2003, 32_450, 0.66, 8014)\n",
    "\n",
    "# Demo Execution\n",
    "print(\"Pattern Matching Examples:\")\n",
    "print(handle_command(['BEEPER', 440, 3]))\n",
    "print(handle_command(['LED', 1, 0.7]))\n",
    "\n",
    "print(\"\\nCartesian Product (List vs Generator):\")\n",
    "print(\"List:\", tshirts_list)\n",
    "print(\"Generator (converted):\", list(tshirts_gen))\n",
    "\n",
    "print(\"\\nSlicing Examples:\")\n",
    "for name, result in slice_examples.items():\n",
    "    print(f\"{name}: {result}\")\n",
    "\n",
    "print(\"\\nNamed Slice Invoice Parsing:\")\n",
    "for line in invoice.split('\\n'):\n",
    "    print(f\"SKU: {line[SKU]} | Price: {line[PRICE]}\")\n",
    "\n",
    "print(\"\\nTuple Unpacking:\")\n",
    "print(f\"Coordinates: {lax_coordinates}\")\n",
    "print(f\"Tokyo Data: {city}, {year}, {pop}, {chg}, {area}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Pattern Matching**:\n",
    "   - Use `match/case` for structural pattern matching (Python 3.10+).\n",
    "   - Destructures sequences and checks patterns with guards.\n",
    "\n",
    "2. **Cartesian Products**:\n",
    "   - Listcomps build full products: `[(c, s) for c in colors for s in sizes]`\n",
    "   - Generators save memory: `(c, s) for c in colors for s in sizes`\n",
    "\n",
    "3. **Slicing**:\n",
    "   - `s[start:stop:step]` supports negative indices and steps.\n",
    "   - Use `slice()` objects for named, reusable slices in complex data parsing.\n",
    "\n",
    "4. **Tuples**:\n",
    "   - Immutable records with fixed-size, ordered fields.\n",
    "   - Unpack tuples for clean variable assignment: `city, year, pop = ...`\n",
    "\n",
    "5. **Performance**:\n",
    "   - Generators avoid memory overhead for large datasets.\n",
    "   - Slicing creates views, not copies (except for strings/bytes).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Sequences, Generators, Tuples, and Pattern Matching\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from random import choice\n",
    "\n",
    "# === FrenchDeck: Emulating Built-in Sequences ===\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits \n",
    "                      for rank in self.ranks]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]\n",
    "\n",
    "# === Vector: Emulating Numeric Types ===\n",
    "class Vector:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Vector({self.x!r}, {self.y!r})'\n",
    "    \n",
    "    def __abs__(self):\n",
    "        return math.hypot(self.x, self.y)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Vector(self.x + other.x, self.y + other.y)\n",
    "    \n",
    "    def __mul__(self, scalar):\n",
    "        return Vector(self.x * scalar, self.y * scalar)\n",
    "\n",
    "# === List Comprehensions vs Generator Expressions ===\n",
    "symbols = '$¢£¥€¤'\n",
    "codes_list = [ord(symbol) for symbol in symbols]  # List comprehension\n",
    "codes_gen = (ord(symbol) for symbol in symbols)    # Generator expression\n",
    "\n",
    "# === Tuples as Records and Immutable Lists ===\n",
    "lax_coordinates = (33.9425, -118.408056)  # Tuple as record\n",
    "immutable_tuple = (10, 'alpha', (1, 2))     # Fully immutable\n",
    "mutable_tuple = (10, 'alpha', [1, 2])       # Contains mutable list\n",
    "\n",
    "# === Pattern Matching with Sequences (Python 3.10+) ===\n",
    "def handle_command(command):\n",
    "    match command:\n",
    "        case ['BEEPER', freq, times]: return f\"Beep {times}x at {freq}Hz\"\n",
    "        case ['NECK', angle]: return f\"Rotate neck to {angle}°\"\n",
    "        case ['LED', id, intensity]: return f\"Set LED {id} brightness to {intensity}\"\n",
    "        case _: return \"Unknown command\"\n",
    "\n",
    "# === Slicing Examples ===\n",
    "s = 'bicycle'\n",
    "slice_examples = {\n",
    "    \"Basic slice\": s[2:5],\n",
    "    \"Full step\": s[::3],\n",
    "    \"Reverse\": s[::-1],\n",
    "    \"Custom slice\": s[1:6:2]\n",
    "}\n",
    "\n",
    "# === Named Slice Objects (Invoice Example) ===\n",
    "invoice = \"\"\"1909 Pimoroni PiBrella $17.50 3 $52.50\n",
    "1489 6mm Tactile Switch x20 $4.95 2 $9.90\"\"\"\n",
    "SKU = slice(0, 6)\n",
    "PRICE = slice(40, 52)\n",
    "\n",
    "# === Cartesian Products ===\n",
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "tshirts_list = [(c, s) for c in colors for s in sizes]  # List comprehension\n",
    "tshirts_gen = ((c, s) for c in colors for s in sizes)   # Generator expression\n",
    "\n",
    "# === Augmented Assignment Gotcha with Tuples ===\n",
    "t = (1, 2, [30, 40])\n",
    "try:\n",
    "    t[2] += [50, 60]  # Triggers TypeError but modifies the tuple\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "\n",
    "# === Demo Execution ===\n",
    "deck = FrenchDeck()\n",
    "v1 = Vector(2, 4)\n",
    "v2 = Vector(2, 1)\n",
    "\n",
    "print(\"FrenchDeck Features:\")\n",
    "print(f\"Random card: {choice(deck)}\")\n",
    "print(f\"Top 3 cards: {deck[:3]}\")\n",
    "\n",
    "print(\"\\nVector Operations:\")\n",
    "print(f\"v1 + v2 = {v1 + v2}\")\n",
    "print(f\"abs(v1) = {abs(v1)}\")\n",
    "print(f\"v1 * 3 = {v1 * 3}\")\n",
    "\n",
    "print(\"\\nTuples as Records:\")\n",
    "print(\"Coordinates:\", lax_coordinates)\n",
    "print(\"Immutable tuple:\", immutable_tuple)\n",
    "print(\"Mutable tuple (after modification):\", (mutable_tuple[0], mutable_tuple[1], mutable_tuple[2] + [99]))\n",
    "\n",
    "print(\"\\nCartesian Product:\")\n",
    "print(\"List comprehension:\", tshirts_list)\n",
    "print(\"Generator expression (converted):\", list(tshirts_gen))\n",
    "\n",
    "print(\"\\nPattern Matching Examples:\")\n",
    "print(handle_command(['BEEPER', 440, 3]))\n",
    "print(handle_command(['LED', 1, 0.7]))\n",
    "\n",
    "print(\"\\nSlicing Examples:\")\n",
    "for name, result in slice_examples.items():\n",
    "    print(f\"{name}: {result}\")\n",
    "\n",
    "print(\"\\nNamed Slice Invoice Parsing:\")\n",
    "for line in invoice.split('\\n'):\n",
    "    print(f\"SKU: {line[SKU]} | Price: {line[PRICE]}\")\n",
    "\n",
    "print(\"\\nTuple Mutation Gotcha:\")\n",
    "print(\"Original tuple t:\", t)\n",
    "print(\"Modified inner list:\", t[2])\n",
    "\n",
    "# === Memory Comparison ===\n",
    "list_size = sys.getsizeof([1, 2, 3])\n",
    "tuple_size = sys.getsizeof((1, 2, 3))\n",
    "print(f\"\\nMemory Usage (bytes): List={list_size}, Tuple={tuple_size}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dunder Methods**:\n",
    "   - `__len__` and `__getitem__` make classes behave like sequences (e.g., `len(deck)`, `deck[0]`).\n",
    "\n",
    "2. **List Comprehensions vs Generators**:\n",
    "   - Use `[]` for immediate computation, `()` for lazy evaluation.\n",
    "   - Generators save memory for large datasets (e.g., `array.array('d', (ord(s)...)`).\n",
    "\n",
    "3. **Tuples**:\n",
    "   - **As Records**: Fixed-size, ordered fields (e.g., coordinates, city data).\n",
    "   - **Caveat**: Tuples with mutable elements (e.g., lists) can change indirectly.\n",
    "\n",
    "4. **Pattern Matching (Python 3.10+)**:\n",
    "   - `match/case` simplifies complex conditionals with destructuring (e.g., handling nested data structures).\n",
    "\n",
    "5. **Slicing**:\n",
    "   - `s[start:stop:step]` supports negative indices and steps.\n",
    "   - Use `slice()` objects for named, reusable slices in complex data parsing.\n",
    "\n",
    "6. **Performance**:\n",
    "   - Tuples use ~40% less memory than lists for small data.\n",
    "   - Listcomps are faster than `map/filter` for Python-level code.\n",
    "\n",
    "7. **Gotchas**:\n",
    "   - Augmented assignment (`+=`) on tuples with mutable elements raises `TypeError` but modifies the inner list.\n",
    "   - `a * n` with mutable items creates multiple references to the same object (e.g., ` [[]] * 3`).\n",
    "\n",
    "8. **Design Patterns**:\n",
    "   - Prefer tuples for data that shouldn't change (e.g., configuration, constants).\n",
    "   - Use listcomps for small datasets; generators for streaming/large data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Advanced Sequences, Memoryviews, and Pattern Matching\n",
    "import collections\n",
    "import array\n",
    "import numpy as np\n",
    "\n",
    "# === Deque Operations (collections.deque) ===\n",
    "dq = collections.deque(range(10), maxlen=10)\n",
    "dq.rotate(3)          # Move right items to left\n",
    "dq.appendleft(-1)     # Bounded deque discards from right\n",
    "dq.extend([11, 22])   # Full deque demonstration\n",
    "\n",
    "# === Memoryview Manipulation ===\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "memv = memoryview(numbers)\n",
    "memv_oct = memv.cast('B')  # View as bytes\n",
    "memv_oct[5] = 4            # Modify byte directly\n",
    "\n",
    "# === NumPy Array Basics ===\n",
    "np_array = np.arange(12).reshape(3, 4)  # 3x4 matrix\n",
    "row = np_array[2]                     # Row access\n",
    "element = np_array[2, 1]              # Element access\n",
    "column = np_array[:, 1]               # Column access\n",
    "transposed = np_array.T               # Transpose\n",
    "\n",
    "# === Sorting: list.sort() vs sorted() ===\n",
    "fruits = ['grape', 'raspberry', 'apple', 'banana']\n",
    "sorted_fruits = sorted(fruits)        # Returns new list\n",
    "fruits.sort(reverse=True)             # In-place sort\n",
    "\n",
    "# === Structural Pattern Matching (Python 3.10+) ===\n",
    "def handle_command(cmd):\n",
    "    match cmd:\n",
    "        case ['BEEPER', freq, times]: return f\"Beep {times}x at {freq}Hz\"\n",
    "        case ['LED', id, *rest]: return f\"LED {id} with {rest}\"\n",
    "        case _: return \"Unknown command\"\n",
    "\n",
    "# === Demo Execution ===\n",
    "print(\"Deque Operations:\")\n",
    "print(\"Original deque:\", dq)\n",
    "print(\"After rotation and appends:\", dq)\n",
    "\n",
    "print(\"\\nMemoryview Modification:\")\n",
    "print(\"Original array:\", numbers)\n",
    "print(\"Modified array:\", array.array('h', memv.tolist()))\n",
    "\n",
    "print(\"\\nNumPy Array Manipulation:\")\n",
    "print(\"Original array:\\n\", np_array)\n",
    "print(\"Row [2]:\", row)\n",
    "print(\"Element [2,1]:\", element)\n",
    "print(\"Transposed array:\\n\", transposed)\n",
    "\n",
    "print(\"\\nSorting Examples:\")\n",
    "print(\"sorted() result:\", sorted_fruits)\n",
    "print(\"In-place sorted list:\", fruits)\n",
    "\n",
    "print(\"\\nPattern Matching Example:\")\n",
    "print(handle_command(['BEEPER', 440, 3]))\n",
    "print(handle_command(['LED', 1, 'ON', 50]))\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Deque Efficiency**:\n",
    "   - Use `collections.deque` for O(1) appends/pops from both ends.\n",
    "   - `maxlen` creates bounded deques that discard old items when full.\n",
    "\n",
    "2. **Memoryviews**:\n",
    "   - Zero-copy views of array data (`memoryview(array)`).\n",
    "   - Cast to different data types (`cast('B')` for bytes).\n",
    "   - Direct byte manipulation without copying underlying data.\n",
    "\n",
    "3. **NumPy Arrays**:\n",
    "   - Vectorized operations avoid explicit loops (e.g., `np.arange()`, `reshape()`).\n",
    "   - Efficient multidimensional indexing and transposing.\n",
    "   - Ideal for numerical data processing vs. native Python lists.\n",
    "\n",
    "4. **Sorting**:\n",
    "   - `list.sort()` sorts in-place and returns `None`.\n",
    "   - `sorted()` returns a new sorted list.\n",
    "   - Use `key=` and `reverse=` parameters for custom sorting.\n",
    "\n",
    "5. **Pattern Matching**:\n",
    "   - `match/case` simplifies complex conditionals (Python 3.10+).\n",
    "   - Destructures sequences with guards and wildcards (`_`).\n",
    "\n",
    "6. **Mutable vs Immutable**:\n",
    "   - `+=`/`*=` behavior differs: \n",
    "     - Lists (mutable): in-place modification\n",
    "     - Tuples (immutable): creates new objects\n",
    "   - Augmented assignment can have side effects with nested mutable elements.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df9c7c",
   "metadata": {},
   "source": [
    "### CHAPTER 3: Dictionaries and Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Dictionaries, Dict Comprehensions, and Pattern Matching\n",
    "\n",
    "# === 1. Dict Comprehensions ===\n",
    "dial_codes = [\n",
    "    (880, 'Bangladesh'),\n",
    "    (55, 'Brazil'),\n",
    "    (86, 'China'),\n",
    "    (91, 'India'),\n",
    "    (62, 'Indonesia'),\n",
    "    (81, 'Japan'),\n",
    "    (234, 'Nigeria'),\n",
    "    (92, 'Pakistan'),\n",
    "    (7, 'Russia'),\n",
    "    (1, 'United States'),\n",
    "]\n",
    "\n",
    "# Simple dict comprehension\n",
    "country_dial = {country: code for code, country in dial_codes}\n",
    "# Filtered and transformed dict comprehension\n",
    "filtered_dial = {code: country.upper() for country, code in sorted(country_dial.items()) if code < 70}\n",
    "\n",
    "# === 2. Unpacking Mappings (PEP 448) ===\n",
    "def dump(**kwargs):\n",
    "    \"\"\"Demonstrates unpacking multiple mappings in function calls\"\"\"\n",
    "    return kwargs\n",
    "\n",
    "# Unpacking in function calls\n",
    "unpacked_func = dump(**{'x': 1}, y=2, **{'z': 3})\n",
    "\n",
    "# Unpacking in dict literals\n",
    "unpacked_dict = {'a': 0, **{'x': 1}, 'y': 2, **{'z': 3, 'x': 4}}  # Note x:4 overwrites x:1\n",
    "\n",
    "# === 3. Merging Mappings with | (Python 3.9+) ===\n",
    "d1 = {'a': 1, 'b': 3}\n",
    "d2 = {'a': 2, 'b': 4, 'c': 6}\n",
    "\n",
    "# Create new merged mapping\n",
    "merged_dict = d1 | d2  # {'a': 2, 'b': 4, 'c': 6}\n",
    "\n",
    "# In-place update\n",
    "d1 |= d2  # Updates d1 with d2's values\n",
    "\n",
    "# === 4. Pattern Matching with Mappings (Python 3.10+) ===\n",
    "def get_creators(record):\n",
    "    \"\"\"Extracts creator names from various media records using pattern matching\"\"\"\n",
    "    match record:\n",
    "        case {'type': 'book', 'api': 2, 'authors': [*names]}:\n",
    "            return names\n",
    "        case {'type': 'book', 'api': 1, 'author': name}:\n",
    "            return [name]\n",
    "        case {'type': 'book'}:\n",
    "            raise ValueError(f\"Invalid 'book' record: {record!r}\")\n",
    "        case {'type': 'movie', 'director': name}:\n",
    "            return [name]\n",
    "        case _:\n",
    "            raise ValueError(f'Invalid record: {record!r}')\n",
    "\n",
    "# === Demo Execution ===\n",
    "print(\"Dict Comprehensions:\")\n",
    "print(\"Country to dial code mapping:\", country_dial)\n",
    "print(\"Filtered dial codes (<70):\", filtered_dial)\n",
    "\n",
    "print(\"\\nUnpacking Mappings:\")\n",
    "print(\"Function unpacking result:\", unpacked_func)\n",
    "print(\"Dict literal unpacking result:\", unpacked_dict)\n",
    "\n",
    "print(\"\\nMerging Mappings:\")\n",
    "print(\"Original d1:\", {'a': 1, 'b': 3})\n",
    "print(\"d2:\", d2)\n",
    "print(\"d1 | d2 (merged):\", merged_dict)\n",
    "print(\"d1 after |= d2:\", d1)\n",
    "\n",
    "print(\"\\nPattern Matching Examples:\")\n",
    "# Book with API 1\n",
    "b1 = dict(api=1, author='Douglas Hofstadter', type='book', title='Gödel, Escher, Bach')\n",
    "print(\"Book (API 1) creators:\", get_creators(b1))\n",
    "\n",
    "# Book with API 2\n",
    "from collections import OrderedDict\n",
    "b2 = OrderedDict(api=2, type='book', title='Python in a Nutshell', \n",
    "                authors='Martelli Ravenscroft Holden'.split())\n",
    "print(\"Book (API 2) creators:\", get_creators(b2))\n",
    "\n",
    "# Movie example\n",
    "m1 = {'type': 'movie', 'director': 'Christopher Nolan'}\n",
    "print(\"Movie creators:\", get_creators(m1))\n",
    "\n",
    "# Extra key handling example\n",
    "food = dict(category='ice cream', flavor='vanilla', cost=199)\n",
    "match food:\n",
    "    case {'category': 'ice cream', **details}:\n",
    "        print(f\"\\nIce cream details (capturing extra keys): {details}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dict Comprehensions**:\n",
    "   - Format: `{key: value for item in iterable}`\n",
    "   - Can include filtering (`if` clause) and transformations\n",
    "   - More readable than `dict()` constructor for complex transformations\n",
    "\n",
    "2. **Unpacking Mappings** (PEP 448):\n",
    "   - Use `**` to unpack multiple dictionaries in function calls and literals\n",
    "   - In function calls: duplicate keys cause errors (no duplicates allowed)\n",
    "   - In dict literals: later keys overwrite earlier ones (e.g., `{'x':1, **{'x':4}}` → `{'x':4}`)\n",
    "\n",
    "3. **Merging Mappings** (Python 3.9+):\n",
    "   - `|` creates a new merged dictionary (right-side keys overwrite left-side)\n",
    "   - `|=` updates a dictionary in-place with another's contents\n",
    "   - Works with any mapping types (not just `dict`)\n",
    "\n",
    "4. **Pattern Matching with Mappings** (Python 3.10+):\n",
    "   - Mapping patterns match by key presence, not order (unlike sequence patterns)\n",
    "   - Partial matches succeed (extra keys are ignored)\n",
    "   - Use `**details` to capture extra key-value pairs\n",
    "   - Ideal for processing semi-structured data (JSON, API responses)\n",
    "\n",
    "5. **Best Practices**:\n",
    "   - Include type/version fields in data records for robust pattern matching\n",
    "   - Always include validation/catch-all cases in pattern matching\n",
    "   - Dict comprehensions improve readability when transforming data\n",
    "   - Use mapping merging operators for cleaner dictionary operations\n",
    "\n",
    "6. **Important Notes**:\n",
    "   - Pattern matching uses `.get()` internally, so it doesn't trigger missing-key handlers\n",
    "   - Mapping patterns are more flexible than sequence patterns (order-independent)\n",
    "   - Dict comprehensions are evaluated immediately (unlike generator expressions)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Mapping Types, Hashability, and Advanced Dictionary Features\n",
    "\n",
    "import collections\n",
    "import sys\n",
    "from collections.abc import Mapping, MutableMapping\n",
    "\n",
    "# === 1. Hashability Examples ===\n",
    "# Hashable objects have a hash code that never changes during their lifetime\n",
    "# and can be compared to other objects (__hash__ and __eq__ methods)\n",
    "\n",
    "# Hashable examples\n",
    "tt = (1, 2, (30, 40))  # Tuple with immutable elements\n",
    "tf = (1, 2, frozenset([30, 40]))  # Tuple with frozenset\n",
    "\n",
    "# Unhashable example\n",
    "try:\n",
    "    tl = (1, 2, [30, 40])\n",
    "    hash(tl)\n",
    "except TypeError as e:\n",
    "    unhashable_error = str(e)\n",
    "\n",
    "# === 2. Standard Mapping Types ===\n",
    "# Check if objects are instances of Mapping ABCs\n",
    "standard_dict = {}\n",
    "is_mapping = isinstance(standard_dict, Mapping)\n",
    "is_mutable_mapping = isinstance(standard_dict, MutableMapping)\n",
    "\n",
    "# === 3. dict.setdefault() vs dict.get() for updating mutable values ===\n",
    "# Example: Building a word index (mapping word -> list of occurrences)\n",
    "\n",
    "# Suboptimal approach using get()\n",
    "index_get = {}\n",
    "words = \"Python is great. Python is powerful. Python is everywhere.\".split()\n",
    "for position, word in enumerate(words):\n",
    "    # Inefficient: two lookups when word is new, three when word exists\n",
    "    occurrences = index_get.get(word, [])\n",
    "    occurrences.append(position)\n",
    "    index_get[word] = occurrences\n",
    "\n",
    "# Optimal approach using setdefault()\n",
    "index_setdefault = {}\n",
    "for position, word in enumerate(words):\n",
    "    # Efficient: single lookup\n",
    "    index_setdefault.setdefault(word, []).append(position)\n",
    "\n",
    "# === 4. defaultdict for Automatic Default Values ===\n",
    "# Better solution for the word index problem\n",
    "index_defaultdict = collections.defaultdict(list)\n",
    "for position, word in enumerate(words):\n",
    "    index_defaultdict[word].append(position)\n",
    "\n",
    "# === 5. Custom Mapping with __missing__ Method ===\n",
    "class StrKeyDict0(dict):\n",
    "    \"\"\"A custom dictionary that converts non-string keys to strings on lookup\"\"\"\n",
    "    def __missing__(self, key):\n",
    "        if isinstance(key, str):\n",
    "            raise KeyError(key)\n",
    "        return self[str(key)]\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        return key in self.keys() or str(key) in self.keys()\n",
    "\n",
    "# Test the custom dictionary\n",
    "str_key_dict = StrKeyDict0([('2', 'two'), ('4', 'four')])\n",
    "\n",
    "# === 6. Merging Dictionaries (Python 3.9+) ===\n",
    "d1 = {'a': 1, 'b': 2}\n",
    "d2 = {'b': 3, 'c': 4}\n",
    "merged_dict = d1 | d2  # Creates new dict with d2 values overwriting d1\n",
    "d1 |= d2  # In-place update\n",
    "\n",
    "# === 7. Pattern Matching with Mappings (Python 3.10+) ===\n",
    "def get_media_type(record):\n",
    "    \"\"\"Extract media type using pattern matching\"\"\"\n",
    "    match record:\n",
    "        case {'type': 'book', 'api': 2, 'authors': [*names]}:\n",
    "            return f\"Book (API 2) by {', '.join(names)}\"\n",
    "        case {'type': 'book', 'api': 1, 'author': name}:\n",
    "            return f\"Book (API 1) by {name}\"\n",
    "        case {'type': 'movie', 'director': name}:\n",
    "            return f\"Movie directed by {name}\"\n",
    "        case _:\n",
    "            return \"Unknown media type\"\n",
    "\n",
    "# === Demo Execution ===\n",
    "print(\"=== HASHABILITY EXAMPLES ===\")\n",
    "print(f\"Hashable tuple: hash({tt}) = {hash(tt)}\")\n",
    "print(f\"Frozenset-based tuple: hash({tf}) = {hash(tf)}\")\n",
    "print(f\"Unhashable error: {unhashable_error}\\n\")\n",
    "\n",
    "print(\"=== MAPPING TYPE CHECKS ===\")\n",
    "print(f\"Is standard dict a Mapping? {is_mapping}\")\n",
    "print(f\"Is standard dict a MutableMapping? {is_mutable_mapping}\\n\")\n",
    "\n",
    "print(\"=== WORD INDEX EXAMPLES ===\")\n",
    "print(\"Using get():\", index_get)\n",
    "print(\"Using setdefault():\", index_setdefault)\n",
    "print(\"Using defaultdict:\", dict(index_defaultdict), \"\\n\")\n",
    "\n",
    "print(\"=== CUSTOM DICTIONARY EXAMPLE ===\")\n",
    "print(f\"str_key_dict['2'] = {str_key_dict['2']}\")\n",
    "print(f\"str_key_dict[4] = {str_key_dict[4]}\")\n",
    "try:\n",
    "    print(str_key_dict[1])\n",
    "except KeyError as e:\n",
    "    print(f\"str_key_dict[1] raises: KeyError('{e}')\")\n",
    "print(f\"str_key_dict.get(4) = {str_key_dict.get(4)}\")\n",
    "print(f\"2 in str_key_dict? {2 in str_key_dict}\\n\")\n",
    "\n",
    "print(\"=== DICTIONARY MERGING ===\")\n",
    "print(f\"Original d1: {{'a': 1, 'b': 2}}\")\n",
    "print(f\"d2: {{'b': 3, 'c': 4}}\")\n",
    "print(f\"d1 | d2: {merged_dict}\")\n",
    "print(f\"d1 after |= d2: {d1}\\n\")\n",
    "\n",
    "print(\"=== PATTERN MATCHING EXAMPLES ===\")\n",
    "book_api2 = {'type': 'book', 'api': 2, 'authors': ['Martelli', 'Ravenscroft', 'Holden']}\n",
    "book_api1 = {'type': 'book', 'api': 1, 'author': 'Hettinger'}\n",
    "movie = {'type': 'movie', 'director': 'Nolan'}\n",
    "print(f\"Book (API 2): {get_media_type(book_api2)}\")\n",
    "print(f\"Book (API 1): {get_media_type(book_api1)}\")\n",
    "print(f\"Movie: {get_media_type(movie)}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Hashability**:\n",
    "   - An object is hashable if it has a hash code that never changes during its lifetime (__hash__ method) \n",
    "     and can be compared to other objects (__eq__ method).\n",
    "   - Numeric types and immutable flat types (str, bytes) are hashable.\n",
    "   - Container types are hashable only if they are immutable and all contained objects are hashable.\n",
    "   - Tuples are hashable only if all items are hashable (e.g., (1, 2, [30, 40]) is unhashable).\n",
    "\n",
    "2. **Mapping ABCs**:\n",
    "   - Use `isinstance(obj, Mapping)` to check if an object behaves as a mapping (supports key lookups).\n",
    "   - Use `isinstance(obj, MutableMapping)` to check if an object supports in-place modifications.\n",
    "   - These ABCs help write more generic code that works with any mapping type.\n",
    "\n",
    "3. **Efficient Mutable Value Updates**:\n",
    "   - Use `dict.setdefault(key, []).append(value)` for single-lookup updates to mutable values.\n",
    "   - Avoid the inefficient pattern: `d[key] = d.get(key, []) + [value]` (multiple lookups).\n",
    "\n",
    "4. **defaultdict**:\n",
    "   - Automatically creates default values for missing keys using a factory function (e.g., `defaultdict(list)`).\n",
    "   - Only triggers for `d[key]` lookups, not for `d.get(key)` or `key in d`.\n",
    "\n",
    "5. **__missing__ Method**:\n",
    "   - Custom mappings can implement `__missing__` to handle missing keys in `__getitem__`.\n",
    "   - Not automatically called by `get()` or `__contains__`, so those methods need custom implementations.\n",
    "\n",
    "6. **Dictionary Merging** (Python 3.9+):\n",
    "   - `|` creates a new merged dictionary (right-side keys overwrite left-side).\n",
    "   - `|=` updates a dictionary in-place with another's contents.\n",
    "\n",
    "7. **Pattern Matching** (Python 3.10+):\n",
    "   - Mapping patterns match by key presence (order-independent).\n",
    "   - Partial matches succeed (extra keys are ignored).\n",
    "   - Use `**details` to capture extra key-value pairs.\n",
    "\n",
    "8. **Best Practices**:\n",
    "   - Prefer `collections.UserDict` over direct `dict` subclassing for custom mappings.\n",
    "   - Use `defaultdict` when you need automatic default values for missing keys.\n",
    "   - Use `setdefault()` for efficient updates of mutable values in standard dictionaries.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62720067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: __missing__ Method Behavior & Dictionary Variations\n",
    "\n",
    "import collections\n",
    "from types import MappingProxyType\n",
    "import sys\n",
    "\n",
    "# === 1. Inconsistent __missing__ Behavior Across Dictionary Implementations ===\n",
    "\n",
    "# Case 1: Subclassing dict (only __missing__ implemented)\n",
    "class DictSubclass(dict):\n",
    "    def __missing__(self, key):\n",
    "        return f\"dict subclass: default for {key}\"\n",
    "\n",
    "d_dict = DictSubclass()\n",
    "print(\"=== dict Subclass ===\")\n",
    "print(f\"d_dict['x'] (uses __missing__): {d_dict['x']}\")\n",
    "print(f\"d_dict.get('y') (ignores __missing__): {d_dict.get('y')}\")\n",
    "print(f\"'z' in d_dict (ignores __missing__): {'z' in d_dict}\\n\")\n",
    "\n",
    "# Case 2: Subclassing UserDict (only __missing__ implemented)\n",
    "class UserDictSubclass(collections.UserDict):\n",
    "    def __missing__(self, key):\n",
    "        return f\"UserDict subclass: default for {key}\"\n",
    "\n",
    "d_userdict = UserDictSubclass()\n",
    "print(\"=== UserDict Subclass ===\")\n",
    "print(f\"d_userdict['x'] (uses __missing__): {d_userdict['x']}\")\n",
    "print(f\"d_userdict.get('y') (uses __missing__): {d_userdict.get('y')}\")\n",
    "print(f\"'z' in d_userdict (uses __missing__): {'z' in d_userdict}\\n\")\n",
    "\n",
    "# Case 3: Minimal Mapping subclass with __missing__ but no __getitem__ call\n",
    "class MinimalMapping(collections.abc.Mapping):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.data = dict(*args, **kwargs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]  # Doesn't call __missing__\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __missing__(self, key):\n",
    "        return f\"MinimalMapping: default for {key}\"\n",
    "\n",
    "d_minimal = MinimalMapping()\n",
    "print(\"=== Minimal Mapping Subclass ===\")\n",
    "try:\n",
    "    print(f\"d_minimal['x'] (no __missing__): {d_minimal['x']}\")\n",
    "except KeyError as e:\n",
    "    print(f\"d_minimal['x'] raises: KeyError('{e}')\")\n",
    "try:\n",
    "    print(f\"d_minimal.get('y') (not implemented): {d_minimal.get('y')}\")\n",
    "except AttributeError as e:\n",
    "    print(f\"d_minimal.get('y') raises: {e}\")\n",
    "print(f\"'z' in d_minimal (works): {'z' in d_minimal}\\n\")\n",
    "\n",
    "# === 2. StrKeyDict: Subclassing UserDict (Better Approach) ===\n",
    "class StrKeyDict(collections.UserDict):\n",
    "    \"\"\"Always converts non-string keys to str on insertion, update, and lookup\"\"\"\n",
    "    def __missing__(self, key):\n",
    "        if isinstance(key, str):\n",
    "            raise KeyError(key)\n",
    "        return self[str(key)]\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        return str(key) in self.data\n",
    "    \n",
    "    def __setitem__(self, key, item):\n",
    "        self.data[str(key)] = item\n",
    "\n",
    "# Test StrKeyDict\n",
    "str_key_dict = StrKeyDict([('2', 'two'), ('4', 'four')])\n",
    "print(\"=== StrKeyDict (UserDict Subclass) ===\")\n",
    "print(f\"str_key_dict['2']: {str_key_dict['2']}\")\n",
    "print(f\"str_key_dict[4]: {str_key_dict[4]}\")\n",
    "print(f\"str_key_dict.get(4): {str_key_dict.get(4)}\")\n",
    "print(f\"2 in str_key_dict: {2 in str_key_dict}\")\n",
    "str_key_dict[5] = 'five'  # Key automatically converted to string\n",
    "print(f\"After str_key_dict[5] = 'five', keys: {list(str_key_dict.keys())}\\n\")\n",
    "\n",
    "# === 3. Dictionary Variations in Standard Library ===\n",
    "# OrderedDict\n",
    "ordered_dict = collections.OrderedDict([('a', 1), ('b', 2), ('c', 3)])\n",
    "ordered_dict.move_to_end('a')  # Move to end\n",
    "print(\"=== OrderedDict ===\")\n",
    "print(f\"OrderedDict after move_to_end: {list(ordered_dict.items())}\")\n",
    "print(f\"Equality with regular dict: {ordered_dict == {'a': 1, 'b': 2, 'c': 3}}\\n\")\n",
    "\n",
    "# ChainMap\n",
    "d1 = {'a': 1, 'b': 3}\n",
    "d2 = {'b': 2, 'c': 4}\n",
    "chain = collections.ChainMap(d1, d2)\n",
    "print(\"=== ChainMap ===\")\n",
    "print(f\"chain['a']: {chain['a']}\")  # From d1\n",
    "print(f\"chain['c']: {chain['c']}\")  # From d2\n",
    "chain['d'] = 5  # Only affects d1\n",
    "print(f\"After chain['d'] = 5, d1: {d1}\\n\")\n",
    "\n",
    "# Counter\n",
    "counter = collections.Counter('abracadabra')\n",
    "counter.update('aaaaazzz')\n",
    "print(\"=== Counter ===\")\n",
    "print(f\"Counter after updates: {counter}\")\n",
    "print(f\"Most common 3 items: {counter.most_common(3)}\\n\")\n",
    "\n",
    "# Immutable Mapping (MappingProxyType)\n",
    "original_dict = {'read': 'only', 'this': 'cannot', 'be': 'changed'}\n",
    "read_only = MappingProxyType(original_dict)\n",
    "print(\"=== Immutable Mapping (MappingProxyType) ===\")\n",
    "print(f\"read_only['read']: {read_only['read']}\")\n",
    "try:\n",
    "    read_only['new'] = 'value'\n",
    "except TypeError as e:\n",
    "    print(f\"Attempt to modify read_only: {e}\")\n",
    "original_dict['new'] = 'value'  # Original can still be modified\n",
    "print(f\"After modifying original, read_only['new']: {read_only['new']}\\n\")\n",
    "\n",
    "# === 4. Memory Comparison of Dictionary Types ===\n",
    "standard_dict = sys.getsizeof({})\n",
    "ordered_dict_size = sys.getsizeof(collections.OrderedDict())\n",
    "user_dict_size = sys.getsizeof(collections.UserDict())\n",
    "\n",
    "print(\"=== Memory Usage (bytes) ===\")\n",
    "print(f\"Standard dict: {standard_dict}\")\n",
    "print(f\"OrderedDict: {ordered_dict_size}\")\n",
    "print(f\"UserDict: {user_dict_size}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **__missing__ Inconsistency**:\n",
    "   - In `dict` subclasses: Only triggered by `d[k]`, not `d.get(k)` or `k in d`\n",
    "   - In `UserDict` subclasses: Triggered by `d[k]`, `d.get(k)`, and `k in d`\n",
    "   - In custom `Mapping` subclasses: Depends on implementation of `__getitem__`\n",
    "\n",
    "2. **Subclassing Strategy**:\n",
    "   - Prefer `collections.UserDict` over `dict` for custom mappings\n",
    "   - `UserDict` uses composition (internal `data` dict) rather than inheritance\n",
    "   - Avoids recursion issues and simplifies implementation\n",
    "\n",
    "3. **Dictionary Variations**:\n",
    "   - `OrderedDict`: Preserves insertion order, supports `move_to_end()`\n",
    "   - `ChainMap`: Searches multiple mappings as one (updates affect only first mapping)\n",
    "   - `Counter`: Specialized for counting hashable objects (multiset functionality)\n",
    "   - `MappingProxyType`: Creates read-only, dynamic proxy of a dictionary\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Implement `__setitem__` when subclassing to handle key transformations\n",
    "   - Use `MappingProxyType` for immutable mappings (dynamic but read-only)\n",
    "   - `UserDict` provides better inheritance model for custom mappings than `dict`\n",
    "   - Always consider whether you need the specific features of a specialized mapping\n",
    "\n",
    "5. **Important Notes**:\n",
    "   - `setdefault()` and `update()` behavior depends on underlying key lookup logic\n",
    "   - `OrderedDict` equality checks for matching order (unlike regular `dict`)\n",
    "   - `ChainMap` is ideal for nested scope implementations (e.g., language interpreters)\n",
    "   - `Counter` implements `+`, `-`, and `most_common()` for tally operations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1269906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Dictionary Views, Sets, and Advanced Operations\n",
    "\n",
    "# === 1. Dictionary Views ===\n",
    "d = dict(a=10, b=20, c=30)\n",
    "keys_view = d.keys()\n",
    "values_view = d.values()\n",
    "items_view = d.items()\n",
    "\n",
    "print(\"=== DICTIONARY VIEWS ===\")\n",
    "print(f\"Original dictionary: {d}\")\n",
    "print(f\"Keys view: {keys_view}\")\n",
    "print(f\"Values view: {values_view}\")\n",
    "print(f\"Items view: {items_view}\")\n",
    "\n",
    "# Demonstrate dynamic nature of views (changes reflect automatically)\n",
    "d['z'] = 99\n",
    "print(f\"\\nAfter adding 'z': {d}\")\n",
    "print(f\"Keys view (updated): {keys_view}\")\n",
    "print(f\"Values view (updated): {values_view}\")\n",
    "print(f\"Items view (updated): {items_view}\")\n",
    "\n",
    "# Views are not subscriptable\n",
    "try:\n",
    "    print(f\"Attempting to index view: {values_view[0]}\")\n",
    "except TypeError as e:\n",
    "    print(f\"Error when indexing view: {e}\")\n",
    "\n",
    "# === 2. Set Operations on Dictionary Views ===\n",
    "d1 = dict(a=1, b=2, c=3, d=4)\n",
    "d2 = dict(b=20, d=40, e=50)\n",
    "\n",
    "print(\"\\n=== SET OPERATIONS ON DICT VIEWS ===\")\n",
    "print(f\"d1: {d1}\")\n",
    "print(f\"d2: {d2}\")\n",
    "\n",
    "# Intersection of keys (common keys)\n",
    "common_keys = d1.keys() & d2.keys()\n",
    "print(f\"Common keys (d1 & d2): {common_keys}\")\n",
    "\n",
    "# Keys unique to d1\n",
    "d1_only = d1.keys() - d2.keys()\n",
    "print(f\"Keys in d1 but not d2: {d1_only}\")\n",
    "\n",
    "# Union of keys\n",
    "all_keys = d1.keys() | d2.keys()\n",
    "print(f\"All keys (union): {all_keys}\")\n",
    "\n",
    "# Symmetric difference (keys in either dict but not both)\n",
    "sym_diff = d1.keys() ^ d2.keys()\n",
    "print(f\"Symmetric difference: {sym_diff}\")\n",
    "\n",
    "# Set operations with regular sets\n",
    "s = {'a', 'e', 'i'}\n",
    "print(f\"\\nRegular set: {s}\")\n",
    "print(f\"d1.keys() & s: {d1.keys() & s}\")\n",
    "print(f\"d1.keys() | s: {d1.keys() | s}\")\n",
    "\n",
    "# Note: dict_items works as a set only if all values are hashable\n",
    "items_intersect = d1.items() & d2.items()\n",
    "print(f\"\\nd1.items() & d2.items(): {items_intersect}\")\n",
    "\n",
    "# === 3. Sets and Set Operations ===\n",
    "print(\"\\n=== SETS AND SET OPERATIONS ===\")\n",
    "# Set literals (note: empty set requires set(), not {})\n",
    "s1 = {1, 2, 3, 4}\n",
    "s2 = {3, 4, 5, 6}\n",
    "print(f\"Set s1: {s1}\")\n",
    "print(f\"Set s2: {s2}\")\n",
    "\n",
    "# Basic set operations\n",
    "print(f\"Union (s1 | s2): {s1 | s2}\")\n",
    "print(f\"Intersection (s1 & s2): {s1 & s2}\")\n",
    "print(f\"Difference (s1 - s2): {s1 - s2}\")\n",
    "print(f\"Symmetric difference (s1 ^ s2): {s1 ^ s2}\")\n",
    "\n",
    "# Set predicates\n",
    "print(f\"\\ns1 is subset of {s1 | s2}? {s1 <= (s1 | s2)}\")\n",
    "print(f\"s1 is proper subset of {s1 | s2}? {s1 < (s1 | s2)}\")\n",
    "print(f\"Are s1 and {s2 - s1} disjoint? {s1.isdisjoint(s2 - s1)}\")\n",
    "\n",
    "# Set comprehensions\n",
    "from unicodedata import name\n",
    "sign_chars = {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i), '')}\n",
    "print(f\"\\nSet comprehension (Unicode SIGN characters): {sign_chars}\")\n",
    "\n",
    "# === 4. Practical Applications ===\n",
    "print(\"\\n=== PRACTICAL APPLICATIONS ===\")\n",
    "# Removing duplicates while preserving order (Python 3.7+)\n",
    "items = ['spam', 'spam', 'eggs', 'spam', 'bacon', 'eggs']\n",
    "unique_ordered = list(dict.fromkeys(items))\n",
    "print(f\"Original list: {items}\")\n",
    "print(f\"Unique items (preserving order): {unique_ordered}\")\n",
    "\n",
    "# Efficient membership testing\n",
    "needles = {'spam', 'eggs', 'ham'}\n",
    "haystack = {'spam', 'eggs', 'bacon', 'toast'}\n",
    "found = len(needles & haystack)\n",
    "print(f\"\\nNeedles: {needles}\")\n",
    "print(f\"Haystack: {haystack}\")\n",
    "print(f\"Found {found} needles in haystack (using set intersection)\")\n",
    "\n",
    "# Counting occurrences with set operations\n",
    "fruits = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple']\n",
    "fruit_set = set(fruits)\n",
    "print(f\"\\nFruits list: {fruits}\")\n",
    "print(f\"Fruit types: {fruit_set}\")\n",
    "print(f\"Count of unique fruits: {len(fruit_set)}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Dictionary Views**:\n",
    "   - `dict.keys()`, `dict.values()`, `dict.items()` return dynamic views that update automatically when the dictionary changes\n",
    "   - Views are read-only projections of dictionary internals (avoid memory overhead of copying data)\n",
    "   - `dict_values` supports only iteration and length checking (no set operations)\n",
    "   - `dict_keys` and `dict_items` support full set operations (intersection, union, etc.)\n",
    "   - Views are not subscriptable (`view[0]` raises TypeError)\n",
    "\n",
    "2. **Set Operations on Dict Views**:\n",
    "   - Use `&` to find common keys: `d1.keys() & d2.keys()`\n",
    "   - Use `-` to find keys unique to one dictionary: `d1.keys() - d2.keys()`\n",
    "   - Dict views work seamlessly with regular sets: `d1.keys() & {'a', 'e', 'i'}`\n",
    "   - `dict_items` only works as a set if all values are hashable\n",
    "   - These operations are highly efficient (O(1) or O(n) time complexity)\n",
    "\n",
    "3. **Sets**:\n",
    "   - Create sets with `{}` (non-empty) or `set()` (empty); `{}` creates a dict\n",
    "   - Set operations: union (`|`), intersection (`&`), difference (`-`), symmetric difference (`^`)\n",
    "   - Set predicates: subset (`<=`), proper subset (`<`), disjoint (`isdisjoint()`)\n",
    "   - Set comprehensions: `{expr for item in iterable if condition}` (e.g., Unicode character filtering)\n",
    "   - Set literals (`{1, 2, 3}`) are faster than `set([1, 2, 3])` due to optimized bytecode\n",
    "\n",
    "4. **Practical Applications**:\n",
    "   - Remove duplicates while preserving order: `list(dict.fromkeys(seq))` (Python 3.7+)\n",
    "   - Efficient membership testing: `if x in my_set` is O(1) regardless of set size\n",
    "   - Count occurrences with intersection: `len(needles & haystack)`\n",
    "   - Use set operations to simplify complex conditional logic and eliminate loops\n",
    "   - Pattern matching with dictionary views enables clean processing of structured data\n",
    "\n",
    "5. **Implementation Details**:\n",
    "   - Sets and dict views use hash tables for O(1) average-case membership testing\n",
    "   - Set elements and dict keys must be hashable (immutable and with proper __hash__/__eq__)\n",
    "   - Dictionary key ordering is preserved (officially guaranteed since Python 3.7)\n",
    "   - Set operations on views avoid creating intermediate lists, saving memory and time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef58f8",
   "metadata": {},
   "source": [
    "### CHAPTER 4: Unicode Text Versus Bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Unicode Text vs Bytes - Comprehensive Guide\n",
    "\n",
    "# === 1. Character Issues: Code Points vs Bytes ===\n",
    "# Unicode separates character identity (code point) from byte representation (encoding)\n",
    "cafe = 'café'  # 4 Unicode characters (code points)\n",
    "print(f\"Original string: '{cafe}' | Length: {len(cafe)}\")\n",
    "\n",
    "# Encode to bytes using different encodings\n",
    "utf8_bytes = cafe.encode('utf-8')\n",
    "utf16_bytes = cafe.encode('utf-16')\n",
    "latin1_bytes = cafe.encode('latin-1')\n",
    "\n",
    "print(f\"\\nUTF-8 encoding: {utf8_bytes} | Length: {len(utf8_bytes)}\")\n",
    "print(f\"UTF-16 encoding: {utf16_bytes} | Length: {len(utf16_bytes)}\")\n",
    "print(f\"LATIN-1 encoding: {latin1_bytes} | Length: {len(latin1_bytes)}\")\n",
    "\n",
    "# Decode back to string\n",
    "print(f\"Decoded from UTF-8: {utf8_bytes.decode('utf-8')}\")\n",
    "print(f\"Decoded from UTF-16: {utf16_bytes.decode('utf-16')}\")\n",
    "\n",
    "# === 2. Byte Essentials: bytes and bytearray ===\n",
    "# Creating bytes objects\n",
    "cafe_bytes = bytes('café', encoding='utf_8')\n",
    "print(f\"\\nBytes object: {cafe_bytes}\")\n",
    "print(f\"First byte (as int): {cafe_bytes[0]}\")\n",
    "print(f\"First byte (as slice): {cafe_bytes[:1]}\")  # Returns bytes, not str\n",
    "\n",
    "# Creating and modifying bytearray\n",
    "cafe_bytearray = bytearray(cafe_bytes)\n",
    "print(f\"\\nBytearray: {cafe_bytearray}\")\n",
    "cafe_bytearray[-1] = 0xa9  # Change é to ©\n",
    "print(f\"Modified bytearray: {cafe_bytearray}\")\n",
    "print(f\"Decoded modified bytearray: {cafe_bytearray.decode('utf-8')}\")\n",
    "\n",
    "# Using string methods on binary sequences\n",
    "print(f\"\\nBytes startswith 'caf': {cafe_bytes.startswith(b'caf')}\")\n",
    "print(f\"Bytes replace é with i: {cafe_bytes.replace(b'\\xc3\\xa9', b'i')}\")\n",
    "\n",
    "# Building bytes from hex\n",
    "hex_bytes = bytes.fromhex('41 42 43 44 45')\n",
    "print(f\"\\nBytes from hex: {hex_bytes} | Decoded: {hex_bytes.decode('ascii')}\")\n",
    "\n",
    "# === 3. Encoding Examples with Different Codecs ===\n",
    "city = 'São Paulo'\n",
    "print(f\"\\n\\nEncoding '{city}' with different codecs:\")\n",
    "print(f\"UTF-8: {city.encode('utf-8')}\")\n",
    "print(f\"UTF-16: {city.encode('utf-16')}\")\n",
    "print(f\"LATIN-1: {city.encode('latin-1')}\")\n",
    "try:\n",
    "    print(f\"CP437: {city.encode('cp437')}\")\n",
    "except UnicodeEncodeError as e:\n",
    "    print(f\"CP437 error: {e}\")\n",
    "\n",
    "# === 4. Error Handling During Encoding ===\n",
    "print(\"\\nEncoding error handling:\")\n",
    "print(f\"Ignore errors: {city.encode('cp437', errors='ignore')}\")\n",
    "print(f\"Replace errors: {city.encode('cp437', errors='replace')}\")\n",
    "print(f\"XML charref: {city.encode('cp437', errors='xmlcharrefreplace')}\")\n",
    "\n",
    "# === 5. Error Handling During Decoding ===\n",
    "octets = b'Montr\\xe9al'\n",
    "print(f\"\\nDecoding b'Montr\\\\xe9al' with different codecs:\")\n",
    "print(f\"CP1252: {octets.decode('cp1252')}\")  # Correct for French\n",
    "print(f\"ISO-8859-7: {octets.decode('iso8859_7')}\")  # Greek encoding (incorrect)\n",
    "print(f\"KOI8-R: {octets.decode('koi8_r')}\")  # Russian encoding (incorrect)\n",
    "try:\n",
    "    print(f\"UTF-8: {octets.decode('utf-8')}\")\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"UTF-8 error: {e}\")\n",
    "print(f\"UTF-8 with replace: {octets.decode('utf-8', errors='replace')}\")\n",
    "\n",
    "# === 6. Practical Text Handling Examples ===\n",
    "# Checking if string is pure ASCII\n",
    "ascii_check = \"Hello, World!\"\n",
    "non_ascii = \"Héllö, Wørld!\"\n",
    "print(f\"\\nIs '{ascii_check}' ASCII? {ascii_check.isascii()}\")\n",
    "print(f\"Is '{non_ascii}' ASCII? {non_ascii.isascii()}\")\n",
    "\n",
    "# Using memoryview for efficient byte manipulation\n",
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "memv = memoryview(numbers)\n",
    "print(f\"\\nArray: {numbers}\")\n",
    "print(f\"Memoryview as bytes: {bytes(memv)}\")\n",
    "print(f\"Memoryview as list: {memv.tolist()}\")\n",
    "\n",
    "# === 7. Unicode Normalization Example ===\n",
    "from unicodedata import normalize, combining, name\n",
    "# Two ways to represent 'é': U+00E9 (single code point) or U+0065 + U+0301 (e + acute)\n",
    "e_acute1 = 'é'  # U+00E9\n",
    "e_acute2 = 'e\\u0301'  # e + COMBINING ACUTE ACCENT\n",
    "\n",
    "print(f\"\\nTwo representations of 'é':\")\n",
    "print(f\"e_acute1: '{e_acute1}' | Length: {len(e_acute1)} | Code point: U+{ord(e_acute1):04X}\")\n",
    "print(f\"e_acute2: '{e_acute2}' | Length: {len(e_acute2)} | Code points: U+{ord(e_acute2[0]):04X}, U+{ord(e_acute2[1]):04X}\")\n",
    "print(f\"Are they equal? {e_acute1 == e_acute2}\")\n",
    "print(f\"Normalized to NFC: {normalize('NFC', e_acute2) == e_acute1}\")\n",
    "print(f\"Normalized to NFD: {normalize('NFD', e_acute1) == e_acute2}\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "1. **Character vs Bytes**:\n",
    "   - Unicode characters have code points (U+XXXX), but their byte representation depends on encoding\n",
    "   - Encoding: str → bytes (text to bytes)\n",
    "   - Decoding: bytes → str (bytes to text)\n",
    "   - UTF-8 is the most common encoding (97% of websites as of 2021)\n",
    "\n",
    "2. **Byte Essentials**:\n",
    "   - `bytes` is immutable, `bytearray` is mutable\n",
    "   - Each item in bytes/bytearray is an integer (0-255), not a character\n",
    "   - Slicing bytes produces bytes, not str (unlike Python 2 str behavior)\n",
    "   - Binary sequences support most string methods (except formatting and Unicode-specific ones)\n",
    "\n",
    "3. **Encoding/Decoding Errors**:\n",
    "   - `UnicodeEncodeError`: When converting str to bytes with unsupported characters\n",
    "   - `UnicodeDecodeError`: When converting bytes to str with invalid byte sequences\n",
    "   - Error handlers: 'strict' (default), 'ignore', 'replace', 'xmlcharrefreplace'\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Always specify encoding when opening files: `open('file.txt', encoding='utf-8')`\n",
    "   - Use UTF-8 whenever possible for maximum compatibility\n",
    "   - Check if text is ASCII with `str.isascii()` (Python 3.7+)\n",
    "   - Normalize Unicode text (NFC/NFD) for reliable comparisons\n",
    "   - Use memoryview for efficient byte manipulation without copying\n",
    "\n",
    "5. **Unicode Features**:\n",
    "   - Use `unicodedata.normalize()` for consistent text comparison\n",
    "   - `unicodedata.name()` helps identify characters by name\n",
    "   - Case folding (`str.casefold()`) is better than `str.lower()` for Unicode text\n",
    "   - For proper sorting, use locale-aware methods or pyuca library\n",
    "\n",
    "6. **Critical Insight**:\n",
    "   - Python 3's strict separation of str and bytes prevents silent data corruption\n",
    "   - Never assume encoding - always specify it explicitly\n",
    "   - Not all bytes are valid text - be cautious when decoding binary data as text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab48e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Unicode Normalization, Case Folding & Sorting\n",
    "\n",
    "import unicodedata\n",
    "import locale\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# === 1. Unicode Normalization for Reliable Comparisons ===\n",
    "# Unicode has multiple ways to represent the same visual character\n",
    "s1 = 'café'  # Precomposed 'é' (U+00E9)\n",
    "s2 = 'cafe\\u0301'  # 'e' + COMBINING ACUTE ACCENT (U+0301)\n",
    "print(\"=== UNICODE NORMALIZATION ===\")\n",
    "print(f\"Original strings: '{s1}' (len={len(s1)}), '{s2}' (len={len(s2)})\")\n",
    "print(f\"Direct comparison: s1 == s2? {s1 == s2}\")\n",
    "\n",
    "# Normalize using different forms\n",
    "nfc_s1 = unicodedata.normalize('NFC', s1)\n",
    "nfc_s2 = unicodedata.normalize('NFC', s2)\n",
    "nfd_s1 = unicodedata.normalize('NFD', s1)\n",
    "nfd_s2 = unicodedata.normalize('NFD', s2)\n",
    "\n",
    "print(f\"\\nNFC normalization: '{nfc_s1}' (len={len(nfc_s1)}), '{nfc_s2}' (len={len(nfc_s2)})\")\n",
    "print(f\"NFC comparison: {nfc_s1 == nfc_s2}\")\n",
    "print(f\"NFD normalization: '{nfd_s1}' (len={len(nfd_s1)}), '{nfd_s2}' (len={len(nfd_s2)})\")\n",
    "print(f\"NFD comparison: {nfd_s1 == nfd_s2}\")\n",
    "\n",
    "# Compatibility normalization (NFKC/NFKD)\n",
    "half = '\\N{VULGAR FRACTION ONE HALF}'  # '½'\n",
    "four_squared = '4²'\n",
    "micro = 'µ'\n",
    "\n",
    "print(f\"\\nCompatibility normalization examples:\")\n",
    "print(f\"'½' (NFKC): {unicodedata.normalize('NFKC', half)}\")\n",
    "print(f\"'4²' (NFKC): {unicodedata.normalize('NFKC', four_squared)}\")\n",
    "print(f\"'µ' (NFKC): {unicodedata.normalize('NFKC', micro)}\")\n",
    "\n",
    "# === 2. Case Folding vs Lowercase ===\n",
    "print(\"\\n=== CASE FOLDING ===\")\n",
    "eszett = 'ß'  # German Eszett\n",
    "micro = 'µ'   # Micro sign\n",
    "\n",
    "print(f\"German 'ß' (casefold): {eszett.casefold()} (vs lower: {eszett.lower()})\")\n",
    "print(f\"Micro sign 'µ' (casefold): {micro.casefold()} (vs lower: {micro.lower()})\")\n",
    "\n",
    "# === 3. Utility Functions for Text Matching ===\n",
    "print(\"\\n=== TEXT MATCHING UTILITIES ===\")\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    \"\"\"Case-sensitive comparison using NFC normalization\"\"\"\n",
    "    return unicodedata.normalize('NFC', str1) == unicodedata.normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    \"\"\"Case-insensitive comparison using NFC normalization + case folding\"\"\"\n",
    "    return (unicodedata.normalize('NFC', str1).casefold() == \n",
    "            unicodedata.normalize('NFC', str2).casefold())\n",
    "\n",
    "# Test the functions\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "\n",
    "print(f\"nfc_equal('café', 'cafe\\\\u0301'): {nfc_equal(s1, s2)}\")\n",
    "print(f\"nfc_equal('Straße', 'strasse'): {nfc_equal(s3, s4)}\")\n",
    "print(f\"fold_equal('Straße', 'strasse'): {fold_equal(s3, s4)}\")\n",
    "print(f\"fold_equal('café', 'cafe\\\\u0301'): {fold_equal(s1, s2)}\")\n",
    "\n",
    "# === 4. Removing Diacritics ===\n",
    "print(\"\\n=== DIACRITIC REMOVAL ===\")\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks from any text\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove diacritic marks only from Latin characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    preserve = []\n",
    "    \n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue  # Skip diacritic on Latin base char\n",
    "        preserve.append(c)\n",
    "        \n",
    "        # Check if it's a new base character\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    return unicodedata.normalize('NFC', ''.join(preserve))\n",
    "\n",
    "# Test diacritic removal\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "greek = 'Ζέφυρος, Zéfiro'\n",
    "\n",
    "print(f\"Original: {order}\")\n",
    "print(f\"Shaved marks: {shave_marks(order)}\")\n",
    "print(f\"Shaved Latin marks only: {shave_marks_latin(order)}\")\n",
    "print(f\"Greek text (full shaving): {shave_marks(greek)}\")\n",
    "\n",
    "# === 5. Unicode Sorting ===\n",
    "print(\"\\n=== UNICODE SORTING ===\")\n",
    "\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "print(f\"Standard sort: {sorted(fruits)}\")\n",
    "\n",
    "# Try locale-based sorting (may not work on all systems)\n",
    "try:\n",
    "    # Set Portuguese/Brazil locale\n",
    "    locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "    sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "    print(f\"Locale sort (pt_BR.UTF-8): {sorted_fruits}\")\n",
    "except (locale.Error, ValueError):\n",
    "    print(\"Locale 'pt_BR.UTF-8' not available on this system\")\n",
    "\n",
    "# Alternative: Using pyuca (Unicode Collation Algorithm)\n",
    "try:\n",
    "    from pyuca import Collator\n",
    "    coll = Collator()\n",
    "    sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "    print(f\"pyuca sort: {sorted_fruits}\")\n",
    "except ImportError:\n",
    "    print(\"pyuca library not installed. Install with: pip install pyuca\")\n",
    "\n",
    "# === 6. Unicode Database Exploration ===\n",
    "print(\"\\n=== UNICODE DATABASE ===\")\n",
    "\n",
    "def find_chars(query_words):\n",
    "    \"\"\"Find Unicode characters by name\"\"\"\n",
    "    query = {w.upper() for w in query_words}\n",
    "    results = []\n",
    "    \n",
    "    for code in range(0x20, 0x10FFFF + 1):\n",
    "        try:\n",
    "            char = chr(code)\n",
    "            name = unicodedata.name(char, None)\n",
    "            if name and query.issubset(name.split()):\n",
    "                results.append((f'U+{code:04X}', char, name))\n",
    "        except (ValueError, UnicodeEncodeError):\n",
    "            pass\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Find smiley characters\n",
    "smileys = find_chars(['SMILE'])\n",
    "print(\"First 5 smiley characters:\")\n",
    "for code, char, name in smileys[:5]:\n",
    "    print(f\"{code}\\t{char}\\t{name}\")\n",
    "\n",
    "# Find circled numbers\n",
    "circled = find_chars(['CIRCLED', 'NUMBER'])\n",
    "print(\"\\nFirst 5 circled numbers:\")\n",
    "for code, char, name in circled[:5]:\n",
    "    print(f\"{code}\\t{char}\\t{name}\")\n",
    "\n",
    "# Get character category\n",
    "char = 'A'\n",
    "category = unicodedata.category(char)\n",
    "print(f\"\\nCategory of '{char}': {category} ({unicodedata.name(char)})\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "\n",
    "1. **Unicode Normalization**:\n",
    "   - Use `unicodedata.normalize('NFC', text)` for most applications\n",
    "   - NFC (Normalization Form C): Composes characters to shortest equivalent\n",
    "   - NFD (Normalization Form D): Decomposes into base + combining characters\n",
    "   - NFKC/NFKD: Stronger forms for compatibility characters (use only for search/indexing)\n",
    "   - Always normalize before comparing Unicode strings\n",
    "\n",
    "2. **Case Folding**:\n",
    "   - Prefer `str.casefold()` over `str.lower()` for case-insensitive comparisons\n",
    "   - Handles special cases like German ß → \"ss\" and µ → \"μ\"\n",
    "   - Essential for reliable internationalized string comparisons\n",
    "\n",
    "3. **Diacritic Removal**:\n",
    "   - `shave_marks()`: Removes all diacritics (may affect non-Latin characters)\n",
    "   - `shave_marks_latin()`: Only removes diacritics from Latin characters\n",
    "   - Useful for creating ASCII-friendly URLs or search indexes\n",
    "   - Use cautiously as it changes word meanings in some languages\n",
    "\n",
    "4. **Unicode Sorting**:\n",
    "   - Standard sorting by code points produces incorrect results for non-ASCII text\n",
    "   - Two main approaches:\n",
    "     * `locale.strxfrm`: OS-dependent, requires proper locale configuration\n",
    "     * `pyuca.Collator`: Pure Python implementation of Unicode Collation Algorithm\n",
    "   - For proper internationalized sorting, always use a specialized collator\n",
    "\n",
    "5. **Unicode Database**:\n",
    "   - Access character metadata with `unicodedata` module\n",
    "   - `unicodedata.name(char)`: Get official Unicode character name\n",
    "   - `unicodedata.category(char)`: Get character category code\n",
    "   - Build utilities to search characters by name (like the `find_chars` function)\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - Normalize text to NFC before storing (W3C recommendation)\n",
    "   - Use NFC + case folding for case-insensitive comparisons\n",
    "   - Never use NFKC/NFKD for permanent storage (data loss)\n",
    "   - For sorting, prefer pyuca over locale for cross-platform consistency\n",
    "   - When removing diacritics, consider language-specific rules\n",
    "\n",
    "7. **Critical Insight**:\n",
    "   - Unicode string processing requires careful handling of normalization\n",
    "   - What looks identical visually may have different code point representations\n",
    "   - Always normalize before comparing, sorting, or indexing Unicode text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbe6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python: Unicode Numeric Characters & Dual-Mode APIs\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "from pathlib import Path\n",
    "\n",
    "# === 1. Numeric Meaning of Unicode Characters ===\n",
    "print(\"=== NUMERIC MEANING OF UNICODE CHARACTERS ===\")\n",
    "\n",
    "# Sample string with various numeric characters\n",
    "sample = '1²⅓\\u0969\\u216b\\u2466\\u3285'  # 1, superscript 2, fraction 1/3, Tamil digit 3, Roman 11, etc.\n",
    "\n",
    "print(f\"Sample string: {sample}\")\n",
    "print(f\"{'Code Point':<10} | {'Char':<5} | {'isdecimal':<10} | {'isnumeric':<10} | {'Numeric Value':<15} | {'Name'}\")\n",
    "\n",
    "for char in sample:\n",
    "    code_point = f'U+{ord(char):04X}'\n",
    "    is_decimal = '✓' if char.isdecimal() else '✗'\n",
    "    is_numeric = '✓' if char.isnumeric() else '✗'\n",
    "    numeric_value = unicodedata.numeric(char) if char.isnumeric() else 'N/A'\n",
    "    char_name = unicodedata.name(char, 'UNKNOWN')\n",
    "    \n",
    "    print(f\"{code_point:<10} | {char:<5} | {is_decimal:<10} | {is_numeric:<10} | {numeric_value:<15} | {char_name}\")\n",
    "\n",
    "# Regex comparison for digits\n",
    "print(\"\\nRegex comparison for digits:\")\n",
    "re_digits_str = re.compile(r'\\d+')\n",
    "re_digits_bytes = re.compile(rb'\\d+')\n",
    "\n",
    "print(f\"String regex (\\\\d+) matches: {re_digits_str.findall(sample)}\")\n",
    "print(f\"Bytes regex (rb\\\\d+) matches: {re_digits_bytes.findall(sample.encode('utf-8'))}\")\n",
    "\n",
    "# Function to extract numeric values from text\n",
    "def extract_numeric_values(text):\n",
    "    \"\"\"Extract all numeric characters and their values from text\"\"\"\n",
    "    results = []\n",
    "    for char in text:\n",
    "        if char.isnumeric():\n",
    "            try:\n",
    "                value = unicodedata.numeric(char)\n",
    "                results.append((char, value, unicodedata.name(char)))\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "    return results\n",
    "\n",
    "numeric_chars = extract_numeric_values(sample)\n",
    "print(\"\\nExtracted numeric values:\")\n",
    "for char, value, name in numeric_chars:\n",
    "    print(f\"Character: {char}, Value: {value}, Name: {name}\")\n",
    "\n",
    "# === 2. Dual-Mode APIs: str vs bytes ===\n",
    "print(\"\\n=== DUAL-MODE APIs: STR VS BYTES ===\")\n",
    "\n",
    "# Regular expressions with str vs bytes\n",
    "print(\"Regular expressions behavior:\")\n",
    "text_str = \"Ramanujan saw 1729 = 1³ + 12³ = 9³ + 10³.\"\n",
    "text_bytes = text_str.encode('utf-8')\n",
    "\n",
    "# String pattern - matches all numeric characters\n",
    "re_str = re.compile(r'\\d+|\\d+\\.\\d+|\\d+[\\u00B2\\u00B3\\u2070-\\u2079]+')\n",
    "# Bytes pattern - matches only ASCII digits\n",
    "re_bytes = re.compile(rb'\\d+')\n",
    "\n",
    "print(f\"Original text: {text_str}\")\n",
    "print(f\"String regex matches: {re_str.findall(text_str)}\")\n",
    "print(f\"Bytes regex matches: {[m.decode('utf-8') for m in re_bytes.findall(text_bytes)]}\")\n",
    "\n",
    "# OS functions with str vs bytes\n",
    "print(\"\\nOS functions with str vs bytes:\")\n",
    "try:\n",
    "    # Create test file with non-ASCII characters\n",
    "    test_filename = \"digits-of-π.txt\"\n",
    "    Path(test_filename).touch()\n",
    "    \n",
    "    # List directory with str argument\n",
    "    str_listing = os.listdir('.')\n",
    "    print(f\"os.listdir('.') with str: {str_listing}\")\n",
    "    \n",
    "    # List directory with bytes argument\n",
    "    bytes_listing = os.listdir(b'.')\n",
    "    print(f\"os.listdir(b'.') with bytes: {bytes_listing}\")\n",
    "    \n",
    "    # Convert between str and bytes representations\n",
    "    encoded = os.fsencode(test_filename)\n",
    "    decoded = os.fsdecode(encoded)\n",
    "    print(f\"os.fsencode('{test_filename}'): {encoded}\")\n",
    "    print(f\"os.fsdecode({encoded}): '{decoded}'\")\n",
    "    \n",
    "    # Clean up\n",
    "    Path(test_filename).unlink()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"OS operations error: {e}\")\n",
    "    print(\"Note: Some OS operations may fail in restricted environments like notebooks\")\n",
    "\n",
    "# === 3. Practical Unicode Processing Utilities ===\n",
    "print(\"\\n=== PRACTICAL UNICODE PROCESSING UTILITIES ===\")\n",
    "\n",
    "def normalize_and_extract_numbers(text):\n",
    "    \"\"\"Normalize text and extract numeric values\"\"\"\n",
    "    # Normalize to NFKD to decompose characters\n",
    "    normalized = unicodedata.normalize('NFKD', text)\n",
    "    # Extract numeric values\n",
    "    numbers = []\n",
    "    for char in normalized:\n",
    "        if char.isnumeric():\n",
    "            try:\n",
    "                numbers.append(unicodedata.numeric(char))\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "    return numbers\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    \"\"\"Remove diacritics from Latin characters\"\"\"\n",
    "    normalized = unicodedata.normalize('NFD', text)\n",
    "    return ''.join(\n",
    "        c for c in normalized \n",
    "        if not unicodedata.combining(c) or c not in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "    )\n",
    "\n",
    "# Test with real-world examples\n",
    "sample_text = \"Café ½ cup of Œtker™ at 100€, São Paulo, 4²=16\"\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print(f\"Numeric values: {normalize_and_extract_numbers(sample_text)}\")\n",
    "print(f\"Without diacritics: {remove_diacritics(sample_text)}\")\n",
    "\n",
    "# === 4. Unicode Sorting Examples ===\n",
    "print(\"\\n=== UNICODE SORTING EXAMPLES ===\")\n",
    "\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "print(f\"Standard sort: {sorted(fruits)}\")\n",
    "\n",
    "# Try locale-based sorting\n",
    "try:\n",
    "    # Set Portuguese/Brazil locale\n",
    "    locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "    sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "    print(f\"Locale sort (pt_BR.UTF-8): {sorted_fruits}\")\n",
    "except (locale.Error, ValueError):\n",
    "    print(\"Locale 'pt_BR.UTF-8' not available on this system\")\n",
    "\n",
    "# Try pyuca sorting (if installed)\n",
    "try:\n",
    "    from pyuca import Collator\n",
    "    coll = Collator()\n",
    "    sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "    print(f\"pyuca sort: {sorted_fruits}\")\n",
    "except ImportError:\n",
    "    print(\"pyuca library not installed. Install with: pip install pyuca\")\n",
    "\n",
    "\"\"\"\n",
    "KEY TAKEAWAYS:\n",
    "\n",
    "1. **Numeric Characters in Unicode**:\n",
    "   - Unicode contains many numeric characters beyond standard digits (0-9)\n",
    "   - `str.isdecimal()` checks for decimal characters (0-9 only)\n",
    "   - `str.isnumeric()` checks for any numeric characters (including fractions, superscripts)\n",
    "   - `unicodedata.numeric(char)` returns the numeric value of a character\n",
    "   - Regex `\\d` matches different characters in str vs bytes patterns\n",
    "\n",
    "2. **Dual-Mode APIs**:\n",
    "   - Many standard library functions work with both str and bytes\n",
    "   - `re` module: str patterns match Unicode characters, bytes patterns match ASCII only\n",
    "   - `os` module: accepts str or bytes for filenames/pathnames\n",
    "   - `os.fsencode()`/`os.fsdecode()` convert between str and bytes representations\n",
    "   - Use bytes mode when dealing with problematic filenames that can't be decoded\n",
    "\n",
    "3. **Practical Processing**:\n",
    "   - Always normalize text (NFC/NFKC) before processing\n",
    "   - Use `unicodedata.normalize('NFKD', text)` to decompose characters for diacritic removal\n",
    "   - For numeric extraction, combine normalization with `isnumeric()` checks\n",
    "   - Case folding (`str.casefold()`) is better than `str.lower()` for Unicode text\n",
    "\n",
    "4. **Sorting Unicode Text**:\n",
    "   - Standard sorting by code points produces incorrect results for non-ASCII text\n",
    "   - Two main approaches:\n",
    "     * `locale.strxfrm`: OS-dependent, requires proper locale configuration\n",
    "     * `pyuca.Collator`: Pure Python implementation of Unicode Collation Algorithm\n",
    "   - For proper internationalized sorting, always use a specialized collator\n",
    "\n",
    "5. **Critical Insights**:\n",
    "   - Unicode numeric values aren't always integers (e.g., fractions like ½ = 0.5)\n",
    "   - Bytes regex patterns only match ASCII digits (0-9), not Unicode numeric characters\n",
    "   - OS filename handling requires special care for non-decodable byte sequences\n",
    "   - Different languages have different sorting rules (e.g., German Ä vs Swedish Ä)\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - Use explicit encoding/decoding everywhere (never rely on defaults)\n",
    "   - Normalize text to NFC before storing (W3C recommendation)\n",
    "   - For numeric processing, consider what \"number\" means in your context\n",
    "   - When removing diacritics, consider language-specific rules\n",
    "   - For international applications, use pyuca for reliable cross-platform sorting\n",
    "\n",
    "7. **Debugging Tips**:\n",
    "   - Use `unicodedata.name(char)` to identify mysterious characters\n",
    "   - Check character categories with `unicodedata.category(char)`\n",
    "   - When debugging encoding issues, print code points: `[ord(c) for c in text]`\n",
    "   - For file issues, check `sys.getfilesystemencoding()` and locale settings\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218642bd",
   "metadata": {},
   "source": [
    "### CHAPTER 5: Data Class Builders\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
